{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to the Sekisui Box\n",
    "sekisui_dir = r'C:\\Users\\$YOURUSERNAME$\\Box\\MIT - Sekisui Collaborative Research'\n",
    "\n",
    "# directory to the matched output data\n",
    "data_dir = r'C:\\$OUTPUT_DATA_DIR$'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOPAC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comprehensive Biopac paths DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_BIOPAC():\n",
    "    \n",
    "    df = pd.DataFrame(columns=['case_id', 'case_dir', 'table_id', 'subject_id', 'year', 'month', 'date', 'file_name'])\n",
    "\n",
    "    for case_id in ['Case1', 'Case2']:\n",
    "        case_dir = case_id + '\\\\from SH to MIT\\\\Biopac'\n",
    "        bp_case_dir = os.path.join(sekisui_dir, case_dir)\n",
    "        table_ids = os.listdir(bp_case_dir)\n",
    "        # print(table_ids)\n",
    "        for t_id in table_ids:\n",
    "            t_dir = os.path.join(bp_case_dir, t_id)\n",
    "            subject_ids = os.listdir(t_dir)\n",
    "            # print(subject_ids)\n",
    "            for s_id in subject_ids:\n",
    "                s_dir = os.path.join(t_dir, s_id)\n",
    "                year_ids = os.listdir(s_dir)\n",
    "                # print(year_ids)\n",
    "                for y_id in year_ids:\n",
    "                    y_dir = os.path.join(s_dir, y_id)\n",
    "                    month_ids = os.listdir(y_dir)\n",
    "                    # print(month_ids)\n",
    "                    for m_id in month_ids:\n",
    "                        # print('month', m_id)\n",
    "                        m_dir = os.path.join(y_dir, m_id)\n",
    "                        date_ids = os.listdir(m_dir)\n",
    "                        # print(date_ids)\n",
    "                        for d_id in date_ids:\n",
    "                            bp_dir = os.path.join(m_dir, d_id)\n",
    "                            bp_file_names = os.listdir(bp_dir)\n",
    "                            # print(bp_file_names)\n",
    "                            for bp_name in bp_file_names:\n",
    "                                if '.csv' in bp_name:\n",
    "                                    df_cat = pd.DataFrame({'case_id': case_id,\n",
    "                                                           'case_dir': case_dir,\n",
    "                                                            'table_id': t_id, \n",
    "                                                            'subject_id': s_id, \n",
    "                                                            'year': y_id, \n",
    "                                                            'month': m_id, \n",
    "                                                            'date': d_id, \n",
    "                                                            'file_name': bp_name\n",
    "                                                            }, index=[0])\n",
    "                                    df = pd.concat([df, df_cat], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_all_BIOPAC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('biopac_search.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process BIOPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(time):\n",
    "    ss = time[-2:]\n",
    "    mm = time[-4:-2]\n",
    "    hh = time[-6:-4]\n",
    "    return hh, mm, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_biopac_name(biopac_name):\n",
    "    biopac_name = biopac_name.replace(\"(\",\"\")\n",
    "    biopac_name = biopac_name.replace(\")\",\"\")\n",
    "    biopac_name = biopac_name.replace(\".csv\",\"\")\n",
    "    biopac_name = biopac_name.split('_')\n",
    "    return biopac_name\n",
    "\n",
    "def parse_biopac_name(biopac_name):\n",
    "    hh,mm,ss = parse_time(biopac_name[-1])\n",
    "    return hh, mm, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_id(x):\n",
    "    for i in x:\n",
    "        if i[:3].lower() == 'act':\n",
    "            return i[3:]\n",
    "\n",
    "def get_action(x):\n",
    "    for i in range(len(x)):\n",
    "        if x[i][:3].lower() != 'act':\n",
    "            action = ''\n",
    "            for j in range(i, len(x)):\n",
    "                action += x[j] + '_'\n",
    "            return action[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df = pd.read_csv('biopac_search.csv')\n",
    "biopac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get split string and length\n",
    "biopac_df['name_split'] = biopac_df['file_name'].apply(split_biopac_name)\n",
    "\n",
    "# get house\n",
    "biopac_df['house'] = biopac_df['subject_id'].apply(lambda x: x[:7])\n",
    "\n",
    "# get room\n",
    "biopac_df['room'] = biopac_df['name_split'].apply(lambda x: x[0].upper())\n",
    "# replace DINNING to DINING\n",
    "biopac_df['room'] = biopac_df['room'].apply(lambda x: 'DINING' if x == 'DINNING' else x)\n",
    "\n",
    "# get time\n",
    "biopac_df['hour'], biopac_df['minute'], biopac_df['second'] = zip(*biopac_df['name_split'].apply(lambda x: parse_time(x[-1])))\n",
    "\n",
    "\n",
    "biopac_df['name_split'] = biopac_df['name_split'].apply(lambda x: x[1:-4])\n",
    "biopac_df['name_split'] = biopac_df['name_split'].apply(lambda x: [i for i in x if i not in ['Biopac', 'biopac', 'Case1', 'Case2']])\n",
    "\n",
    "# get dp_id\n",
    "biopac_df['dp_id'] = biopac_df['name_split'].apply(lambda x: x[1])\n",
    "\n",
    "biopac_df['name_split'] = biopac_df['name_split'].apply(lambda x: x[2:])\n",
    "\n",
    "# get action\n",
    "biopac_df['act_id'] = biopac_df['name_split'].apply(lambda x: get_action_id(x))\n",
    "biopac_df['action'] = biopac_df['name_split'].apply(lambda x: get_action(x))\n",
    "\n",
    "# drop name_split\n",
    "biopac_df = biopac_df.drop(columns=['name_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df.to_csv('biopac_search.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dates_normal(df):\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['month'] = df['month'].astype(str)\n",
    "    df['date'] = df['date'].astype(str)\n",
    "\n",
    "    df['month'] = df['month'].apply(lambda x: '0' + x if len(x) == 1 else x)\n",
    "    df['date'] = df['date'].apply(lambda x: '0' + x if len(x) == 1 else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df = pd.read_csv('biopac_search.csv')\n",
    "biopac_df = make_dates_normal(biopac_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_map = {\n",
    "    'BED_pfh_016': 1,\n",
    "    'BED_pfh_028': 2,\n",
    "    'BED_pfh_031': 3,\n",
    "    'STUDY_pfh_031': 4,\n",
    "    'BED1_pfh_101': 5,\n",
    "    'BED2_pfh_101': 6,\n",
    "    'DINING_pfh_101': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df['room_id'] = None\n",
    "for i in range(len(biopac_df)):\n",
    "    biopac_df.loc[i, 'room_id'] = room_map[biopac_df.loc[i, 'room']+'_'+biopac_df.loc[i, 'house']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_from_csv(file_path):\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for _ in range(7):  # Skip the first 8 lines\n",
    "            next(reader)\n",
    "        for _ in range(7):\n",
    "            line = next(reader)  # Retrieve the 9th line\n",
    "            if line[0] in ['sec', 'min']:\n",
    "                line = next(reader)\n",
    "                return int(line[0])\n",
    "\n",
    "def get_biopac_path(df, row):\n",
    "    case_id = df.loc[row, 'case_id']\n",
    "    table_id = df.loc[row, 'table_id']\n",
    "    subject_id = df.loc[row, 'subject_id']\n",
    "    year = df.loc[row, 'year']\n",
    "    month = df.loc[row, 'month']\n",
    "    date = int(df.loc[row, 'date'])\n",
    "    file_name = df.loc[row, 'file_name']\n",
    "    biopac_path = os.path.join(sekisui_dir, case_id,'from SH to MIT\\\\Biopac', table_id, subject_id, str(year), str(month), str(date), file_name)\n",
    "    return biopac_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_to_skip(file_path):\n",
    "    \"\"\"\n",
    "    This gives us a way to open the biopac files in a consistent manner\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for _ in range(7):  # Skip the first 8 lines\n",
    "            next(reader)\n",
    "        for i in range(7,15):\n",
    "            line = next(reader)  # Retrieve the 9th line\n",
    "            if line[0] in ['sec', 'min']:\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = []\n",
    "\n",
    "for i in tqdm(range(len(biopac_df))):\n",
    "    while True:\n",
    "        try:\n",
    "            csv_path = get_biopac_path(biopac_df, i)\n",
    "            number = get_number_from_csv(csv_path)\n",
    "            if number == 0:\n",
    "                bp_skip = get_rows_to_skip(csv_path)\n",
    "                bp_df = pd.read_csv(csv_path, skiprows=bp_skip)\n",
    "                # drop first row of bp_1\n",
    "                bp_df = bp_df.drop([0])\n",
    "                number = len(bp_df)\n",
    "            duration.append(number)\n",
    "            break\n",
    "        except OSError as e:\n",
    "            if e.errno != 22:\n",
    "                raise\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df['duration'] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df.rename(columns={'hour': 'start_hr',\n",
    "                          'minute':'start_min',\n",
    "                          'second': 'start_sec'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df['start_time_idx'] = biopac_df['start_hr'].astype(int)*3600 + biopac_df['start_min'].astype(int)*60 + biopac_df['start_sec'].astype(int)\n",
    "biopac_df['end_time_idx'] = biopac_df['start_time_idx'] + biopac_df['duration'].astype(int)/250\n",
    "biopac_df['end_time_idx'] = biopac_df['end_time_idx'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df.to_csv('biopac_search.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match doppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_df = pd.read_csv('biopac_search.csv')\n",
    "biopac_df = make_dates_normal(biopac_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doppler_room = pd.read_csv('doppler_room.csv')\n",
    "doppler_map = {i: doppler_room[doppler_room['RoomID']==i]['RadarID'].unique().tolist() for i in range(5,8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dp_folder(df, row, dp_id):\n",
    "    case_id = df.loc[row, 'case_id']\n",
    "    table_id = df.loc[row, 'table_id']\n",
    "    year = df.loc[row, 'year']\n",
    "    month = df.loc[row, 'month']\n",
    "    date = df.loc[row, 'date']\n",
    "    dp_folder = os.path.join(sekisui_dir, case_id,'from SH to MIT\\\\Doppler', table_id)\n",
    "    dp_folder = os.path.join(dp_folder, dp_id)\n",
    "    dp_folder = os.path.join(dp_folder, str(year), str(month), str(date))\n",
    "    return dp_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doppler_name(name):\n",
    "    name = name.replace('.csv','')\n",
    "    name = name.split('_')\n",
    "    time = name[-3]\n",
    "    hh = time[:2]\n",
    "    mm = time[2:4]\n",
    "    ss = time[4:]\n",
    "    start_time_idx = int(hh)*3600 + int(mm)*60 + int(ss)\n",
    "    duration = int(name[-1])\n",
    "    end_time_idx = start_time_idx + duration\n",
    "    return start_time_idx, end_time_idx, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_cols = ['biopac_idx', 'case_id', 'table_id', 'subject_id', 'year', 'month', 'date', \n",
    "               'room', 'act_id', 'action', 'house', 'room_id', 'doppler_id',\n",
    "               'biopac_start_time_idx', 'biopac_end_time_idx', 'doppler_start_time_idx', 'doppler_end_time_idx', \n",
    "               'biopac_file_name', 'doppler_file_name',\n",
    "               'biopac_start_idx', 'biopac_end_idx', 'doppler_start_idx', 'doppler_end_idx', 'overlap_duration']\n",
    "\n",
    "master_df = pd.DataFrame(columns=master_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(biopac_df))):\n",
    "\n",
    "    # get overlapping information\n",
    "    biopac_idx = i\n",
    "    case_id = biopac_df.loc[i, 'case_id']\n",
    "    table_id = biopac_df.loc[i, 'table_id']\n",
    "    subject_id = biopac_df.loc[i, 'subject_id']\n",
    "    year = biopac_df.loc[i, 'year']\n",
    "    month = biopac_df.loc[i, 'month']\n",
    "    date = biopac_df.loc[i, 'date']\n",
    "    room = biopac_df.loc[i, 'room']\n",
    "    act_id = biopac_df.loc[i, 'act_id']\n",
    "    action = biopac_df.loc[i, 'action']\n",
    "    house = biopac_df.loc[i, 'house']\n",
    "    room_id = biopac_df.loc[i, 'room_id']\n",
    "\n",
    "    # get biopac information\n",
    "    biopac_start_time_idx = biopac_df.loc[i, 'start_time_idx']\n",
    "    biopac_end_time_idx = biopac_df.loc[i, 'end_time_idx']\n",
    "    biopac_duration = biopac_df.loc[i, 'duration']\n",
    "    biopac_file_name = biopac_df.loc[i, 'file_name']\n",
    "\n",
    "    # Get doppler ID of all the radars\n",
    "    if biopac_df.loc[i, 'dp_id'] == 'DS-xxxxx':\n",
    "        dp_list = doppler_map[biopac_df.loc[i, 'room_id']]\n",
    "    else:\n",
    "        dp_list = [biopac_df.loc[i, 'dp_id']]\n",
    "    \n",
    "    # get information for each doppler\n",
    "    for doppler_id in dp_list:\n",
    "        dp_folder = get_dp_folder(biopac_df, i, doppler_id)\n",
    "\n",
    "        if not os.path.exists(dp_folder):\n",
    "            continue\n",
    "\n",
    "        dp_files = []\n",
    "        while True:\n",
    "            try:\n",
    "                dp_files = os.listdir(dp_folder)\n",
    "                break  # Break out of the loop if the operation succeeds\n",
    "            except OSError as e:\n",
    "                if e.winerror == 1006:\n",
    "                    time.sleep(1)  # Wait for a second before retrying\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=master_cols)\n",
    "\n",
    "        for dp_file in dp_files:\n",
    "            if '.csv' not in dp_file:\n",
    "                continue\n",
    "\n",
    "            dp_file_name = dp_file\n",
    "\n",
    "            # get overlapping times\n",
    "            dp_start_time_idx, dp_end_time_idx, dp_duration = parse_doppler_name(dp_file)\n",
    "\n",
    "            # 1. doppler starts, biopac starts, doppler ends, biopac ends\n",
    "            if dp_start_time_idx <= biopac_start_time_idx <= dp_end_time_idx <= biopac_end_time_idx:\n",
    "                dp_start_idx = (biopac_start_time_idx - dp_start_time_idx)*1000\n",
    "                biopac_start_idx = 0\n",
    "                overlap_duration = dp_end_time_idx - biopac_start_time_idx\n",
    "\n",
    "            # 2. doppler starts, biopac starts, biopac ends, doppler ends\n",
    "            elif dp_start_time_idx <= biopac_start_time_idx <= biopac_end_time_idx <= dp_end_time_idx:\n",
    "                dp_start_idx = (biopac_start_time_idx - dp_start_time_idx)*1000\n",
    "                biopac_start_idx = 0\n",
    "                overlap_duration = biopac_end_time_idx - biopac_start_time_idx\n",
    "\n",
    "            # 3. biopac starts, doppler starts, biopac ends, doppler ends\n",
    "            elif biopac_start_time_idx <= dp_start_time_idx <= biopac_end_time_idx <= dp_end_time_idx:\n",
    "                biopac_start_idx = (dp_start_time_idx - biopac_start_time_idx)*250\n",
    "                dp_start_idx = 0\n",
    "                overlap_duration = biopac_end_time_idx - dp_start_time_idx\n",
    "\n",
    "            # 4. biopac starts, doppler starts, doppler ends, biopac ends\n",
    "            elif biopac_start_time_idx <= dp_start_time_idx <= dp_end_time_idx <= biopac_end_time_idx:\n",
    "                biopac_start_idx = (dp_start_time_idx - biopac_start_time_idx)*250\n",
    "                dp_start_idx = 0\n",
    "                overlap_duration = dp_end_time_idx - dp_start_time_idx\n",
    "\n",
    "            # 5. if none of the above, then no overlap\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            dp_end_idx = dp_start_idx + overlap_duration*1000\n",
    "            biopac_end_idx = biopac_start_idx + overlap_duration*250\n",
    "\n",
    "            # add to temp_df\n",
    "            temp_df.loc[len(temp_df.index)] = [biopac_idx, case_id, table_id, subject_id,\n",
    "                                            year, month, date,\n",
    "                                            room, act_id, action, house, room_id, doppler_id,\n",
    "                                            biopac_start_time_idx, biopac_end_time_idx,\n",
    "                                            dp_start_time_idx, dp_end_time_idx,\n",
    "                                            biopac_file_name, dp_file_name,\n",
    "                                            biopac_start_idx, biopac_end_idx,\n",
    "                                            dp_start_idx, dp_end_idx,\n",
    "                                            overlap_duration]\n",
    "        \n",
    "        # add to master_df\n",
    "        master_df = pd.concat([master_df, temp_df], ignore_index=True)\n",
    "        master_df.to_csv('master_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by biopac_idx\n",
    "master_df = master_df.sort_values(by=['biopac_idx']).reset_index(drop=True)\n",
    "\n",
    "# remove duplicates from master_df because it stopped half way several times\n",
    "master_df = master_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# add overlap_start_idx\n",
    "master_df['overlap_start_idx'] = master_df['biopac_start_time_idx'] + master_df['biopac_start_idx'] // 250\n",
    "master_df['overlap_end_idx'] = master_df['biopac_start_time_idx'] + master_df['biopac_end_idx'] // 250\n",
    "\n",
    "master_df.to_csv('master_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate into clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('master_df.csv')\n",
    "master_df = make_dates_normal(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doppler_path(df, row):\n",
    "    case_id = df.loc[row, 'case_id']\n",
    "    table_id = df.loc[row, 'table_id']\n",
    "    year = df.loc[row, 'year']\n",
    "    month = df.loc[row, 'month']\n",
    "    date = df.loc[row, 'date']\n",
    "    dp_id = df.loc[row, 'doppler_id']\n",
    "    file_name = df.loc[row, 'doppler_file_name']\n",
    "    doppler_path = os.path.join(sekisui_dir, case_id,'from SH to MIT\\\\Doppler', table_id, dp_id, str(year), str(month), str(date), file_name)\n",
    "    return doppler_path\n",
    "\n",
    "def get_biopac_path(df, row):\n",
    "    case_id = df.loc[row, 'case_id']\n",
    "    table_id = df.loc[row, 'table_id']\n",
    "    subject_id = df.loc[row, 'subject_id']\n",
    "    year = df.loc[row, 'year']\n",
    "    month = df.loc[row, 'month']\n",
    "    date = int(df.loc[row, 'date'])\n",
    "    file_name = df.loc[row, 'biopac_file_name']\n",
    "    biopac_path = os.path.join(sekisui_dir, case_id,'from SH to MIT\\\\Biopac', table_id, subject_id, str(year), str(month), str(date), file_name)\n",
    "    return biopac_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sample points\n",
    "\n",
    "clip_sec = 30\n",
    "\n",
    "total_num = (master_df['overlap_duration'][master_df['overlap_duration'] > clip_sec] // clip_sec).sum()\n",
    "print(f'Total number of data points in 30 second clips: {total_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_num = max(master_df['biopac_idx']) + 1\n",
    "\n",
    "indexed_df = pd.DataFrame(columns=['datapoint_idx','biopac_clip_idx', 'biopac_idx', 'case_id', 'table_id', 'subject_id', 'year', 'month',\n",
    "                                    'date', 'room', 'act_id', 'action', 'house', 'room_id', 'doppler_id',\n",
    "                                    'biopac_start_time_idx', 'biopac_end_time_idx',\n",
    "                                    'doppler_start_time_idx', 'doppler_end_time_idx', 'biopac_file_name',\n",
    "                                    'doppler_file_name', 'biopac_start_idx', 'biopac_end_idx',\n",
    "                                    'doppler_start_idx', 'doppler_end_idx', 'overlap_duration',\n",
    "                                    'overlap_start_idx', 'overlap_end_idx'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just not do anything with the csv, let's just index everything first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_clip_idx = 0\n",
    "datapoint_idx = 0\n",
    "\n",
    "# for each unique biopac file (entire file not clipped)\n",
    "for biopac_i in tqdm(range(biopac_num)):\n",
    "\n",
    "    # get the dopplers corresponding to biopac_i\n",
    "    small_df = master_df[(master_df['biopac_idx'] == biopac_i) & (master_df['overlap_duration'] >= clip_sec)].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(small_df) == 0:\n",
    "        continue\n",
    "\n",
    "    overlap_start_idx = min(small_df['overlap_start_idx'])\n",
    "    overlap_end_idx = max(small_df['overlap_end_idx'])\n",
    "\n",
    "    biopac_start_time_idx = small_df.iloc[0]['biopac_start_time_idx']\n",
    "\n",
    "    overlap_num = (overlap_end_idx - overlap_start_idx) // clip_sec\n",
    "\n",
    "    # check how many clips are in each overlap\n",
    "    for overlap_i in range(overlap_num):\n",
    "\n",
    "        # for each row in small df, i.e. each doppler\n",
    "        for j in range(len(small_df)):\n",
    "\n",
    "            # check if overlap_i is in the doppler's overlap\n",
    "            if small_df.iloc[j]['overlap_start_idx'] > overlap_start_idx + overlap_i*clip_sec:\n",
    "                continue\n",
    "            if small_df.iloc[j]['overlap_end_idx'] < overlap_start_idx + (overlap_i+1)*clip_sec:\n",
    "                continue\n",
    "\n",
    "            dp_start_time_idx = small_df.loc[j, 'doppler_start_time_idx']\n",
    "\n",
    "            indexed_df.loc[datapoint_idx] = [datapoint_idx, biopac_clip_idx] + small_df.iloc[j].tolist()\n",
    "            \n",
    "            indexed_df.loc[datapoint_idx, 'overlap_start_idx'] = overlap_start_idx + overlap_i * clip_sec\n",
    "            indexed_df.loc[datapoint_idx, 'overlap_end_idx'] = overlap_start_idx + (overlap_i+1) * clip_sec\n",
    "            \n",
    "            indexed_df.loc[datapoint_idx, 'biopac_start_idx'] = (overlap_start_idx + overlap_i * clip_sec - biopac_start_time_idx)*250\n",
    "            indexed_df.loc[datapoint_idx, 'biopac_end_idx'] = (overlap_start_idx + (overlap_i+1) * clip_sec - biopac_start_time_idx)*250\n",
    "            indexed_df.loc[datapoint_idx, 'doppler_start_idx'] = (overlap_start_idx + overlap_i * clip_sec - dp_start_time_idx)*1000\n",
    "            indexed_df.loc[datapoint_idx, 'doppler_end_idx'] = (overlap_start_idx + (overlap_i+1) * clip_sec - dp_start_time_idx)*1000\n",
    "\n",
    "            datapoint_idx += 1\n",
    "\n",
    "        biopac_clip_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.to_csv('indexed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopac_list = indexed_df['biopac_idx'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for biopac_i in tqdm(biopac_list, desc='Biopac Files', total=len(biopac_list)):\n",
    "\n",
    "    # get a full biopac file\n",
    "    small_df = indexed_df[indexed_df['biopac_idx'] == biopac_i].copy().reset_index(drop=True)\n",
    "    bp_path = get_biopac_path(small_df, 0)\n",
    "    bp_skip = get_rows_to_skip(bp_path)\n",
    "    bp_df = pd.read_csv(bp_path, skiprows=bp_skip)\n",
    "    # drop first row of bp_1\n",
    "    bp_df = bp_df.drop([0])\n",
    "\n",
    "    dp_list = small_df['doppler_file_name'].unique().tolist()\n",
    "    \n",
    "    for dp_i in dp_list:\n",
    "\n",
    "        smaller_df = small_df[small_df['doppler_file_name'] == dp_i].copy().reset_index(drop=True)\n",
    "\n",
    "        # get doppler data\n",
    "        dp_path = get_doppler_path(smaller_df, 0)\n",
    "        dp_df = pd.read_csv(dp_path, usecols=[0, 1])\n",
    "\n",
    "        for i in range(len(smaller_df)):\n",
    "            # get the starting point of the clip\n",
    "            bp_start = smaller_df.loc[i, 'biopac_start_idx']\n",
    "            dp_start = smaller_df.loc[i, 'doppler_start_idx']\n",
    "\n",
    "            # get the ending point of the clip\n",
    "            bp_end = smaller_df.loc[i, 'biopac_end_idx']\n",
    "            dp_end = smaller_df.loc[i, 'doppler_end_idx']\n",
    "\n",
    "            # get the clip\n",
    "            bp_clip = bp_df.iloc[bp_start:bp_end, :]\n",
    "            dp_clip = dp_df.iloc[dp_start:dp_end, :]\n",
    "\n",
    "            # name the clip\n",
    "            biopac_clip_i = smaller_df.loc[i, 'biopac_clip_idx']\n",
    "            biopac_file_name = 'BIOPAC_'+str(biopac_clip_i)\n",
    "            doppler_file_name = str(smaller_df.loc[i, 'doppler_id'])+str(biopac_clip_i)\n",
    "\n",
    "            # save the clip\n",
    "            datapoint_dir = os.path.join(data_dir, str(biopac_clip_i))\n",
    "            if not os.path.exists(datapoint_dir):\n",
    "                os.makedirs(datapoint_dir, exist_ok=True)\n",
    "                bp_clip.to_csv(os.path.join(datapoint_dir, f'{biopac_file_name}.csv'), index=False)\n",
    "\n",
    "            dp_clip.to_csv(os.path.join(datapoint_dir, f'{doppler_file_name}.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
